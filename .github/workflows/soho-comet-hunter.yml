name: SOHO Comet Hunt

on:
  schedule:
    - cron: "0 * * * *"
    - cron: "*/15 * * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout (full history)
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install opencv-python-headless numpy requests pillow \
                      filterpy scipy imageio imageio-ffmpeg

      # --------------------------------------------------------------
      # 1. REPROCESS OLD REPORTS (adds ai_label)
      # --------------------------------------------------------------
      - name: Reprocess old reports
        env:
          USE_AI_CLASSIFIER: "1"
        run: |
          cat > reprocess_old_reports.py << 'EOF'
          #!/usr/bin/env python3
          import json, os, cv2, numpy as np
          from pathlib import Path

          D = Path("detections")
          USE_AI = os.getenv("USE_AI_CLASSIFIER", "1") == "1"

          def classify(crop):
              if not USE_AI or crop.size == 0:
                  return {"label": "not_comet", "score": 0.0}
              h, w = crop.shape
              center = crop[h//4:3*h//4, w//4:3*w//4]
              if center.size == 0:
                  return {"label": "not_comet", "score": 0.0}
              score = min(0.99, (np.mean(center)/255)*0.6 + (np.std(center)/50)*0.4)
              return {"label": "comet" if score > 0.6 else "not_comet", "score": round(score, 3)}

          for p in sorted(D.glob("candidates_*.json"), reverse=True):
              try:
                  with open(p) as f:
                      data = json.load(f)
              except:
                  continue
              modified = False
              for cand in data:
                  if cand.get("ai_label"):
                      continue
                  cp = Path(cand.get("crop_path", ""))
                  if not cp.is_absolute():
                      cp = D / cp
                  if not cp.exists():
                      continue
                  crop = cv2.imread(str(cp), cv2.IMREAD_GRAYSCALE)
                  if crop is None:
                      continue
                  ai = classify(crop)
                  cand["ai_label"] = ai["label"]
                  cand["ai_score"] = ai["score"]
                  modified = True
              if modified:
                  backup = p.with_suffix(".json.bak")
                  p.rename(backup)
                  with open(p, "w") as f:
                      json.dump(data, f, indent=2)
          EOF
          python reprocess_old_reports.py

      # --------------------------------------------------------------
      # 2. RUN LIVE DETECTION (AI ON)
      # --------------------------------------------------------------
      - name: Run live detection
        env:
          USE_AI_CLASSIFIER: "1"
          DETECTOR_DEBUG: "1"
        run: |
          python detector/detect_comets.py --hours 6 --step-min 12 --out detections
          echo "frames tree:"; find frames -maxdepth 2 -type f -printf "%P\n" | sort | sed 's/^/  - /'
          echo "detections tree:"; find detections -maxdepth 2 -type f -printf "%P\n" | sort | sed 's/^/  - /'

      # --------------------------------------------------------------
      # 3. COMMIT NEW FILES FIRST
      # --------------------------------------------------------------
      - name: Commit new detections
        id: commit
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -n "$(git status --porcelain detections)" ]; then
            git add detections
            git commit -m "Auto: new detections + AI labels [$(date -u +'%Y-%m-%dT%H:%M:%SZ')] [skip ci]"
            echo "committed=true" >> $GITHUB_OUTPUT
          else
            echo "committed=false" >> $GITHUB_OUTPUT
          fi

      # --------------------------------------------------------------
      # 4. PULL REMOTE CHANGES (now safe â€” changes are committed)
      # --------------------------------------------------------------
      - name: Pull latest remote changes
        if: steps.commit.outputs.committed == 'true'
        run: |
          git fetch origin
          git rebase origin/main || (git rebase --abort && exit 1)

      # --------------------------------------------------------------
      # 5. PUSH (safe with force-with-lease)
      # --------------------------------------------------------------
      - name: Push changes
        if: steps.commit.outputs.committed == 'true'
        run: |
          git push origin HEAD:main --force-with-lease

      # --------------------------------------------------------------
      # 6. UPLOAD ARTIFACTS
      # --------------------------------------------------------------
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: detections-${{ github.run_id }}
          path: |
            detections/**/*.json
            detections/animations/*.mp4
            detections/animations/*.gif
          if-no-files-found: warn
          retention-days: 7
